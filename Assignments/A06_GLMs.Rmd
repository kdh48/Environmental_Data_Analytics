---
title: "Assignment 6: Generalized Linear Models"
author: "Kat Horan"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics (ENV872L) on generalized linear models. 

## Directions
1. Change "Student Name" on line 3 (above) with your name.
2. Use the lesson as a guide. It contains code that can be modified to complete the assignment.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
Space for your answers is provided in this document and is indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio. 
6. When you have completed the assignment, **Knit** the text and code into a single PDF file.
You will need to have the correct software installed to do this (see Software Installation Guide)
Press the `Knit` button in the RStudio scripting panel.
This will save the PDF output in your Assignments folder.
8. After Knitting, please submit the completed exercise (PDF file) to the dropbox in Sakai. Please add your last name into the file name (e.g., "Salk_A06_GLMs.pdf") prior to submission.

The completed exercise is due on Tuesday, 26 February, 2019 before class begins.

## Set up your session 
1. Set up your session. Upload the EPA Ecotox dataset for Neonicotinoids and the NTL-LTER raw data file for chemistry/physics. 

2. Build a ggplot theme and set it as your default theme.

```{r}
#1 Set up session

# Set working directory:
# setwd("/Users/kathleenhoran/Desktop/Duke/Spring 2019/Env. Data Analytics/Env_Data_Analytics")

# Load packages:
library(ggplot2)
library(viridis)
library(RColorBrewer)
library(tidyverse)
library(gridExtra)
library(dunn.test)

# Load datasets:
# NTL-LTER for chemistry/physics raw data
NTL.lake.chem.phys.raw <-
  read.csv("./Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv")

# Ecotox for Neonicotinoids raw data
Ecotox.neo.mort.raw <- read.csv("./Data/Raw/ECOTOX_Neonicotinoids_Mortality_raw.csv")

#2 Set ggplot theme
mytheme <- theme_classic(base_size = 14) +
  theme(axis.text = element_text(color = "black"),
        legend.position = "top")
theme_set(mytheme)

```

## Neonicotinoids test
Research question: Were studies on various neonicotinoid chemicals conducted in different years? 

3. Generate a line of code to determine how many different chemicals are listed in the Chemical.Name column.

4. Are the publication years associated with each chemical well-approximated by a normal distribution? Run the appropriate test and also generate a frequency polygon to illustrate the distribution of counts for each year, divided by chemical name. Bonus points if you can generate the results of your test from a pipe function. No need to make this graph pretty.

5. Is there equal variance among the publication years for each chemical? Hint: var.test is not the correct function.

```{r, fig.width = 7.5, fig.height = 4, fig.align= "center"}
#3 Check different chemicals listed in Chemical.Name column 
levels(Ecotox.neo.mort.raw$Chemical.Name)
summary.factor(Ecotox.neo.mort.raw$Chemical.Name)

#4
# Shapiro test for normality for publication years associated with each of the nine chemicals
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Acetamiprid"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Clothianidin"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Dinotefuran"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Imidacloprid"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Imidaclothiz"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Nitenpyram"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Nithiazine"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Thiacloprid"])
shapiro.test(Ecotox.neo.mort.raw$Pub..Year[Ecotox.neo.mort.raw$Chemical.Name == "Thiamethoxam"])

# The publication years are not well-approximated by a normal distribution. 
# Since the p-values generated by the Shapiro-Wilk tests for pub years associated
# with each chemical are all smaller than .05, we reject the null hypothesis of
# normality.

# Frequency polygon
ggplot(Ecotox.neo.mort.raw, aes(x = Pub..Year, color = Chemical.Name)) +
  geom_freqpoly(stat = "count") +
  theme(legend.position = "right")
  
#5 Test for equal variance
bartlett.test(Ecotox.neo.mort.raw$Pub..Year ~ Ecotox.neo.mort.raw$Chemical.Name)

# There is not equal variance among the publication years for each chemical, as
# indicated by the low p-value from the Bartlett test. We accept the Bartlett 
# test's alternative hypothesis that the variances are not equal

```

6. Based on your results, which test would you choose to run to answer your research question?

> ANSWER: I would select the Kruskal Wallace test because it is not normally distributed.

7. Run this test below. 

8. Generate a boxplot representing the range of publication years for each chemical. Adjust your graph to make it pretty.
```{r, fig.width = 7.5, fig.height = 4.5, fig.align= "center"}
#7 Kruskal Wallace test
chem.pub.kw <- kruskal.test(Ecotox.neo.mort.raw$Pub..Year ~ Ecotox.neo.mort.raw$Chemical.Name)
chem.pub.kw

dunn.test(Ecotox.neo.mort.raw$Pub..Year, Ecotox.neo.mort.raw$Chemical.Name, kw = T, 
           table = F, list = T, method = "holm", altp = T)

#8 Boxplot with range of publication years for each chemical
chem.pub.boxplot <-
  ggplot(Ecotox.neo.mort.raw, aes(x = Chemical.Name, y = Pub..Year, color = Chemical.Name)) +
  geom_boxplot() +
  labs(x = "Chemical Name", y = "Publication Year") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_color_viridis(discrete = TRUE) +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45,  hjust = 1))
print(chem.pub.boxplot)

```


9. How would you summarize the conclusion of your analysis? Include a sentence summarizing your findings and include the results of your test in parentheses at the end of the sentence. 

> ANSWER: The p-value smaller than 0.05 from the Kruskal-Wallis test indicates that there is a significant difference between groups. (Kruskal-Wallis chi-squared = 134.1455, df = 8, p-value = 0).

>Since it does not indicate which groups, I ran a Dunn test to see which pairs had the significant difference. We see that the following pairs are significantly different:

> Acetamiprid - Clothianidin  : -3.038807 (0.0404)*
Clothianidin - Dinotefuran  :  4.406076 (0.0002)*
Acetamiprid - Imidacloprid  : -4.020498 (0.0013)*
Dinotefuran - Imidacloprid  : -5.214028 (0.0000)*
Acetamiprid - Nitenpyram    : -4.501863 (0.0002)*
Dinotefuran - Nitenpyram    : -5.452779 (0.0000)*
Imidacloprid - Nitenpyram   : -3.063483 (0.0394)*
Acetamiprid - Nithiazine    :  5.642529 (0.0000)*
Clothianidin - Nithiazine   :  7.147325 (0.0000)*
Dinotefuran - Nithiazine    :  3.869350 (0.0023)*
Imidacloprid - Nithiazine   :  7.728634 (0.0000)*
Imidaclothiz - Nithiazine   :  4.847313 (0.0000)*
Nitenpyram - Nithiazine     :  7.709981 (0.0000)*
Acetamiprid - Thiacloprid   : -3.222561 (0.0241)*
Dinotefuran - Thiacloprid   : -4.602529 (0.0001)*
Nithiazine - Thiacloprid    : -7.316688 (0.0000)*
Acetamiprid - Thiamethoxam  : -5.889886 (0.0000)*
Dinotefuran - Thiamethoxam  : -6.676212 (0.0000)*
Imidacloprid - Thiamethoxam : -3.532703 (0.0082)*
Nithiazine - Thiamethoxam   : -8.722412 (0.0000)*

## NTL-LTER test
Research question: What is the best set of predictors for lake temperatures in July across the monitoring period at the North Temperate Lakes LTER? 

11. Wrangle your NTL-LTER dataset with a pipe function so that it contains only the following criteria: 

* Only dates in July (hint: use the daynum column). No need to consider leap years.
* Only the columns: lakename, year4, daynum, depth, temperature_C
* Only complete cases (i.e., remove NAs)

12. Run an AIC to determine what set of explanatory variables (year4, daynum, depth) is best suited to predict temperature. Run a multiple regression on the recommended set of variables. 

```{r}
#11 Wrangling data set
NTL.lake.chem.phys.processed <- 
  NTL.lake.chem.phys.raw %>%
  filter(daynum >= 182 & daynum <= 212) %>%
  select(lakename, year4, daynum, depth, temperature_C) %>%
  filter(!is.na(temperature_C))

#12 
# AIC tests with all explanatory variables
NTL.lake.chem.phys.AIC <- 
  lm(data = NTL.lake.chem.phys.processed, temperature_C ~ year4 + daynum + depth)
step(NTL.lake.chem.phys.AIC)

# Final multiple regression
NTL.lake.chem.phys.model <- 
  lm(data = NTL.lake.chem.phys.processed, temperature_C ~ year4 + daynum + depth)
summary(NTL.lake.chem.phys.model)
```

13. What is the final linear equation to predict temperature from your multiple regression? How much of the observed variance does this model explain?

> ANSWER: The final linear equation is also the original linear model. The AIC test found that all three explanatory variables were significant and did not find that it needed to be reduced. 74.17% of the variance is explained in this mode.

14. Run an interaction effects ANCOVA to predict temperature based on depth and lakename from the same wrangled dataset.

```{r}
#14 Interaction effects ANCOVA
NTL.lake.chem.phys.ancova.int <- 
  lm(data = NTL.lake.chem.phys.processed, temperature_C ~ lakename * depth)
summary(NTL.lake.chem.phys.ancova.int)

```

15. Is there an interaction between depth and lakename? How much variance in the temperature observations does this explain?

> ANSWER: The low p-value tells us that there is a significant interaction between depth and lakename, and the we can see the specific significant interactions in the summary. The only interaction that is marginally significant is the interaction of depth and Paul Lake at .0966. 78.57% of the variance in temperature observations can be explained by the interaction between depth and lakename.

16. Create a graph that depicts temperature by depth, with a separate color for each lake. Add a geom_smooth (method = "lm", se = FALSE) for each lake. Make your points 50 % transparent. Adjust your y axis limits to go from 0 to 35 degrees. Clean up your graph to make it pretty. 

```{r, fig.width = 7.5, fig.height = 4.5, fig.align= "center"}
#16 Plot with temperature by depth for each lake
tempbydepth.plot <- ggplot(NTL.lake.chem.phys.processed, 
  aes(x = depth, y = temperature_C, color = lakename)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm", se = FALSE) +
  xlim(0, 10) +
  ylim(0, 35) +
  scale_color_brewer(palette = "Paired") +
  labs(x = "Depth", y = "Temperature (Celsius)", 
              fill = "lakename", color = "Lake Name") +
  theme(legend.position = "right")
print(tempbydepth.plot)

```

